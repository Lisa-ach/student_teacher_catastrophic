experiment_name:                    
use_gpu:                            True                      
seed:                               5

network_simulation: False
ode_simulation: True

task:
  label_task_boundaries:            True                      
  learner_configuration:            continual                 # meta or continual - specifies whether student has separate heads for each teacher (continual) or not (meta)
  teacher_configuration:            overlapping               # noisy, independent, overlapping, drifting, trained_mnist (see README)
  num_teachers:                     2                         
  loss_type:                        regression                # classification or regression

training:
  total_training_steps:             500000
  train_batch_size:                 1                         
  learning_rate:                    0.1                                             
  loss_function:                    mse                       # mse, bce
  scale_head_lr:                    True                      # whether to add 1/N factor in lr of output layer  
  scale_hidden_lr:                  True                      # whether to add 1/\sqrt{N} factor in forward of hidden layer(s)
  ode_timestep:             0.01
  train_first_layer:                True
  train_head_layer:                 True

data:
  input_source:                     iid_gaussian              # iid_gaussian, mnist_stream, mnist_digits, even_greater (see README)

logging:
  verbose:                          True                      
  verbose_tb:                       0                         # 0 - no tb logging, 1 - minimal tb logging, 2 - full tb logging                     
  checkpoint_frequency:             5000                      
  log_to_df:                        True
  merge_at_checkpoint:              True
  save_weights_at_switch:           True
  save_initial_weights:             True
  
testing:
  test_batch_size:                  50000                     # generalisation error
  test_frequency:                   1                         # how often during training to perform generalisation error test loop
  overlap_frequency:                100                       # how often during training to compute / visualise overlap matrices

model:
  input_dimension:                  1000                       
  student_hidden_layers:            [30]                       
  teacher_hidden_layers:            [15]                       
  output_dimension:                 1                         
  student_nonlinearity:             scaled_erf                      
  teacher_nonlinearities:           [scaled_erf, scaled_erf]              # per teacher
  normalise_teachers:               True
  teacher_initialisation_std:       1                         # std of normal initialisation for teacher network
  student_initialisation_std:       0.001                     # std of normal initialisation for student network
  unit_norm_teacher_head:           True                      # choose head weight from 1, -1 or initialise using normal
  initialise_student_outputs:       True                     # whether or not to initialise hidden -> output weights of student
  soft_committee:                   False                     # whether or not to fix output layer of student to 1 (scm)
  teacher_bias_parameters:          False                     # whether or not to have bias parameters on linaer layers (teacher)
  student_bias_parameters:          False                     # whether or not to have bias parameters on linaer layers (student)
  symmetric_student_initialisation: False                     # identically initialised student hidden units

curriculum:
  stopping_condition:               fixed_period              # condition on which to switch task (fixed_period or threshold)
  fixed_period:                     250000                      # period for changing tasks 
  loss_thresholds:                   [0.0001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001, 0.000000001, 0.0000000001]                    # loss threshold under which teacher is changed

teachers:
  overlap_type:                     [copy, rotation]
  overlap_rotations:                [3.14159, 0]                 # 0, 2pi = aligned, pi = anti-aligned, pi/2 orthogonal, pi/4 = semi-aligned etc.
  overlap_percentages:              [100, 0]                    # percentage of weights to copy between teachers per layer.
  teacher_noises:                    [0, 0]

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "concerned-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "separated-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = \"\"\n",
    "SEEDS = None # e.g. range(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "continuing-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_organised_paths(results_path, seeds):\n",
    "    timestamps = os.listdir(results_path)\n",
    "    data_logger_paths = {s: {} for s in seeds}\n",
    "    \n",
    "    for timestamp in timestamps:\n",
    "        timestamp_experiments = os.listdir(os.path.join(results_path, timestamp))\n",
    "        for exp in timestamp_experiments:\n",
    "            split_name = exp.split(\"_\")\n",
    "            seed = int(split_name[1][1:])\n",
    "            ra = float(split_name[2][2:])\n",
    "            fa = float(split_name[3][2:])\n",
    "            data_logger_paths[seed][(fa, ra)] = os.path.join(results_path, timestamp, exp, str(seed), \"data_logger.csv\")\n",
    "        \n",
    "    return data_logger_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lightweight-special",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bb28debb81d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0morganised_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_organised_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEEDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-50b7d0c5bffa>\u001b[0m in \u001b[0;36mget_organised_paths\u001b[0;34m(results_path, seeds)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_organised_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtimestamps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata_logger_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "organised_paths = get_organised_paths(RESULTS_PATH, SEEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "novel-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "def test_get_organised_paths():\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        # create dummmy file structure\n",
    "        test_dates = [\"2021-03-31-21-38-00\", \"2021-03-31-21-38-02\"]\n",
    "        test_exp_names = {1: \"exp_s1_ra0.2_fa0.1\", 2: \"exp_s2_ra0.2_fa0.8\"}\n",
    "        for test_date in test_dates:\n",
    "            os.mkdir(os.path.join(tmpdirname, test_date))\n",
    "            for seed, test_exp in test_exp_names.items():\n",
    "                os.mkdir(os.path.join(tmpdirname, test_date, test_exp))\n",
    "                os.mkdir(os.path.join(tmpdirname, test_date, test_exp, str(seed)))\n",
    "                open(os.path.join(tmpdirname, test_date, test_exp, str(seed), \"data_logger.csv\"), 'a').close()\n",
    "\n",
    "        test_data_logger_paths = get_organised_paths(tmpdirname, range(3))\n",
    "\n",
    "    return test_data_logger_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stuffed-cross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {},\n",
       " 1: {(0.2,\n",
       "   0.1): '/var/folders/1x/frtldspx7qd6_bnf97dp310w0000gn/T/tmpalj0igx5/2021-03-31-21-38-00/exp_s1_ra0.2_fa0.1/1/data_logger.csv'},\n",
       " 2: {(0.2,\n",
       "   0.8): '/var/folders/1x/frtldspx7qd6_bnf97dp310w0000gn/T/tmpalj0igx5/2021-03-31-21-38-00/exp_s2_ra0.2_fa0.8/2/data_logger.csv'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_get_organised_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "passive-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df_paths, switch_step, final_step, threshold=None):\n",
    "    dfs = {k: pd.read_csv(df_path) for k, df_path in dfs_paths.items()}\n",
    "    if switch_step is None:\n",
    "        assert threshold is not None, \"No switch step given, must give threshold instead.\"\n",
    "        # infer from threshold\n",
    "        # all first teacher errors should be the same, so take arbitrary one\n",
    "        sample_df = dfs[list(dfs.keys())[0]]\n",
    "        sample_df_first_error = np.array(sample_df.log_generalisation_error_0)\n",
    "        switch_step = np.where(sample_df_first_error < threshold)[0][0] + 1\n",
    "        final_step = len(sample_df)\n",
    "    switch_errors = {k: df.log_generalisation_error_0[switch_step - 1] for k, df in dfs.items()}\n",
    "    final_errors = {k: df.log_generalisation_error_0[final_step - 1] for k, df in dfs.items()}\n",
    "    switch_errors_1 = {k: df.log_generalisation_error_1[switch_step - 1] for k, df in dfs.items()}\n",
    "    final_errors_1 = {k: df.log_generalisation_error_1[final_step - 1] for k, df in dfs.items()}\n",
    "    forgetting = {k: df.log_generalisation_error_0[final_step - 1] - df.log_generalisation_error_0[switch_step - 1] for k, df in dfs.items()}\n",
    "    forgetting_rate = {k: np.mean([df.log_generalisation_error_0[switch_step - 1 + i + 1] - df.log_generalisation_error_0[switch_step - 1 + i] for i in range(10)]) for k, df in dfs.items()}\n",
    "    max_forgetting = {k: np.amax(df.log_generalisation_error_0[switch_step - 1:]) - df.log_generalisation_error_0[switch_step - 1] for k, df in dfs.items()}\n",
    "    second_threshold_steps = {k: np.where(df.log_generalisation_error_1 < switch_errors[k])[0][0] for k, df in dfs.items()}\n",
    "    adjusted_forgetting = {k: df.log_generalisation_error_0[second_threshold_steps[k]] - df.log_generalisation_error_0[switch_step - 1] for k, df in dfs.items()}\n",
    "    transfer = {k: df.log_generalisation_error_1[switch_step - 1] - df.log_generalisation_error_1[final_step - 1] for k, df in dfs.items()}\n",
    "    transfer_rate = {k: np.mean([df.log_generalisation_error_1[switch_step - 1 + i] - df.log_generalisation_error_1[switch_step - 1 + i + 1] for i in range(10)]) for k, df in dfs.items()}\n",
    "    max_transfer = {k: df.log_generalisation_error_1[switch_step - 1] - np.amin(df.log_generalisation_error_1[switch_step - 1:]) for k, df in dfs.items()}\n",
    "    return forgetting, forgetting_rate, max_forgetting, adjusted_forgetting, transfer, transfer_rate, max_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "coastal-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_plot_base(sample_metric):\n",
    "    x, y = np.meshgrid(np.linspace(0, 1, 11), np.linspace(0, 1, 11))\n",
    "    unique_sorted_keys = np.unique([i[0] for i in sorted(list(sample_metric.keys()), key=lambda x: float(x[0]))])\n",
    "    x_overlap_map = {v: i for i, v in enumerate(unique_sorted_keys)}\n",
    "    y_overlap_map = {v: i for i, v in enumerate(np.unique([i[1] for i in sorted(list(sample_metric.keys()), key=lambda x: float(x[1]))]))}\n",
    "    return x_overlap_map, y_overlap_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "chicken-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z(value_dict):\n",
    "    z = np.zeros((11, 11))\n",
    "    \n",
    "    x_overlap_map, y_overlap_map = get_2d_plot_base(value_dict)\n",
    "\n",
    "    for k, f_value in value_dict.items():\n",
    "        x_val = k[0]\n",
    "        y_val = k[1]\n",
    "        x_index = x_overlap_map[x_val]\n",
    "        y_index = y_overlap_map[y_val]\n",
    "        z[x_index][y_index] = f_value\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "creative-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2d(metric, metric_title, cmap, save_name):\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(get_z(metric), origin=\"lower\", extent=[0, 1, 0, 1], cmap=cmap)\n",
    "    plt.xlabel(\"Feature Similarity\")\n",
    "    plt.ylabel(\"Readout Similarity\")\n",
    "    plt.title(metric_title)\n",
    "    plt.colorbar()\n",
    "    fig.show()\n",
    "    fig.savefig(os.path.join(RESULTS_PATH, save_name), dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "allied-venture",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'organised_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-a473be25e8bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_dfs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morganised_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mseed_forgetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_forgetting_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_max_forgetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_adjusted_forgetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_transfer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_transfer_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_max_transfer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswitch_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplot2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_forgetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Forgetting: Seed {seed}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"viridis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"forgetting_seed_{seed}.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplot2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_forgetting_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Forgetting Rate: Seed {seed}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"viridis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"forgetting_rate_seed_{seed}.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplot2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_max_forgetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Max Forgetting: Seed {seed}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"viridis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"max_forgetting_seed_{seed}.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'organised_paths' is not defined"
     ]
    }
   ],
   "source": [
    "for seed, seed_dfs in organised_paths.items():\n",
    "    seed_forgetting, seed_forgetting_rate, seed_max_forgetting, seed_adjusted_forgetting, seed_transfer, seed_transfer_rate, seed_max_transfer = get_metrics(df_paths=seed_dfs, switch_step=None, final_step=None, threshold=-4)\n",
    "    plot2d(seed_forgetting, f\"Forgetting: Seed {seed}\", \"viridis\", f\"forgetting_seed_{seed}.pdf\")\n",
    "    plot2d(seed_forgetting_rate, f\"Forgetting Rate: Seed {seed}\", \"viridis\", f\"forgetting_rate_seed_{seed}.pdf\")\n",
    "    plot2d(seed_max_forgetting, f\"Max Forgetting: Seed {seed}\", \"viridis\", f\"max_forgetting_seed_{seed}.pdf\")\n",
    "    plot2d(seed_transfer, f\"Transfer: Seed {seed}\", \"plasma\", f\"transfer_seed_{seed}.pdf\")\n",
    "    plot2d(seed_transfer_rate, f\"Transfer Rate: Seed {seed}\", \"plasma\", f\"transfer_rate_seed_{seed}.pdf\")\n",
    "    plot2d(seed_max_transfer, f\"Max Transfer: Seed {seed}\", \"plasma\", f\"max_transfer_seed_{seed}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-deficit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cata",
   "language": "python",
   "name": "cata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

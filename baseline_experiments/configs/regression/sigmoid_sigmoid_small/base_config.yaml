experiment_name:                    
use_gpu:                            True                      # whether to use a gpu if it is available on the device          
seed:                               0                         # random seed 
resume:        
verbose:                            True                      # whether to print
verbose_tb:                         False                     # whether to log everything (overlaps etc.) to tb
checkpoint_frequency:               500                       # how often to checkpoint logging dataframe

task:
  label_task_boundaries:            True                      # whether or not to add the task index to the input (extra supervision)
  learner_configuration:            continual                 # meta or continual - specifies whether student has separate heads for each teacher (continual) or not (meta)
  teacher_configuration:            overlapping               # 'noisy': each teacher has same initialisation, each with different levels of noise added, 'independent': all randomly initialised, 'drifting': all randomly initialised but drifting over time, 'overlapping': structured similarity in teacher weights
  num_teachers:                     1                         # number of teachers to use
  loss_type:                        "regression"              # whether loss is classification or regression (whether we take sigmoid and sign of teacher output)

training:
  total_training_steps:             200000                    # total number of training steps to take
  train_batch_size:                 1                         # number of tasks sampled per meta-update (per outer loop)
  test_batch_size:                  50000                     # number of samples to use for generalisatio error
  learning_rate:                    5                         # learning rate for sgd update of student
  loss_function:                    mse                       # function to use for loss
  input_source:                     iid_gaussian              # whether to have inputs drawn randomly or (e.g. from mnist)
  pca_input:                        -1                        # number of principle components to reduce data to (no PCA if -1)                         
  
testing:
  test_frequency:                   1                         # how often during training to perform generalisation error test loop
  overlap_frequency:                100                       # how often during training to compute / visualise overlap matrices
  test_all_teachers:                True                      # whether to compute generalisation losses for all teachers or just one currently teaching

model:
  input_dimension:                  500                       # dimension of network input 
  student_hidden_layers:            [1]                      # dimension of hidden layers to be used in student network
  teacher_hidden_layers:            [1]                      # dimension of hidden layers to be used in teacher network(s)
  output_dimension:                 1                         # dimension of network output
  student_nonlinearity:             sigmoid                      # nonlinearity to be used for networks
  teacher_nonlinearities:           [sigmoid]
  teacher_initialisation_std:       1                         # std of normal initialisation for teacher network
  student_initialisation_std:       0.001                     # std of normal initialisation for student network
  initialise_student_outputs:       False                     # whether or not to initialise hidden -> output weights of student
  soft_committee:                   False                     # whether or not to freeze output layer (scm)
  bias_parameters:                  False                     # whether or not to have bias parameters on linaer layers

curriculum:
  type:                             custom                    # curriculum type (custom - declarative or standard - imperative)
  selection_type:                   cyclical                  # how to determine next task (random or cyclical)
  stopping_condition:               fixed_period              # condition on which to switch task (fixed_period or threshold)

  fixed_period:                     200000                    # period for changing tasks 
  loss_threshold:                   0.0001                    # loss threshold under which teacher is changed 
  custom:                           [0, 1]                    # curriculum defined manually. Each entry defines next teacher index